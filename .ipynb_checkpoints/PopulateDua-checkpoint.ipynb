{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f69e0b",
   "metadata": {},
   "source": [
    "# Populate Dua Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfaee4",
   "metadata": {},
   "source": [
    "## Installing required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1984ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rdflib\n",
    "# !pip install SPARQLWrapper\n",
    "# !pip install owlready2\n",
    "# !pip install PyArabic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd708f8",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22012ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, BNode, Namespace\n",
    "from rdflib.namespace import FOAF, XMLNS, XSD, RDF, RDFS, OWL\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import csv, re, unicodedata\n",
    "# Utility ftn.s and data\n",
    "############################################################\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "from pyarabic.araby import strip_harakat, strip_tashkeel, strip_tatweel, normalize_hamza, tokenize, sentence_tokenize, is_arabicrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2e300",
   "metadata": {},
   "source": [
    "## Loading Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9229f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_Hadith = Graph()\n",
    "g_Hadith.parse('SemanticHadithKG.rdf')\n",
    "hn = Namespace('http://www.i-knex.com/ontology/hadith#')\n",
    "\n",
    "g_Quran = Graph()\n",
    "g_Quran.parse('quran_data_full.ttl', format = 'turtle')\n",
    "qn = Namespace ('http://quranontology.com/Resource/')\n",
    "\n",
    "g_dua = Graph()\n",
    "g_dua.parse('ontology/dua_ontology_final_copy.ttl', format = 'turtle')\n",
    "n = Namespace('http://www.semanticweb.org/szm/dua-ontology#')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2e048",
   "metadata": {},
   "source": [
    "## Related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f359c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_alaf(text):\n",
    "    return text.replace('إ', 'ا')\n",
    "\n",
    "\n",
    "def normalizeArabic(text):\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    return(text)\n",
    "\n",
    "def deNormalize(text):\n",
    "    alifs           = '[إأٱآا]'\n",
    "    alifReg         = '[إأٱآا]'\n",
    "    # -------------------------------------\n",
    "    alifMaqsura     = '[يى]'\n",
    "    alifMaqsuraReg  = '[يى]'\n",
    "    # -------------------------------------\n",
    "    taMarbutas      = 'ة'\n",
    "    taMarbutasReg   = '[هة]'\n",
    "    # -------------------------------------\n",
    "    hamzas          = '[ؤئء]'\n",
    "    hamzasReg       = '[ؤئءوي]'\n",
    "    # Applying deNormalization\n",
    "    text = re.sub(alifs, alifReg, text)\n",
    "    text = re.sub(alifMaqsura, alifMaqsuraReg, text)\n",
    "    text = re.sub(taMarbutas, taMarbutasReg, text)\n",
    "    text = re.sub(hamzas, hamzasReg, text)\n",
    "    return text\n",
    "\n",
    "def deNoise(text):\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd4c58",
   "metadata": {},
   "source": [
    "### Quran Chapters List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0897d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_surah_lis = [\n",
    "['الفاتحة','The Opening'],\n",
    "['البقرة','Al-Baqara'],\n",
    "['آل عمران','Aal-i-Imraan'],\n",
    "['لنساء','An-Nisa'],\n",
    "['المائدة\"','The Table'],\n",
    "['الأنعام','The Cattle'],\n",
    "['الأعراف',\"Al-A'raaf\"],\n",
    "['الأنفال','The Spoils of War'],\n",
    "['التوبة','At-Tawba'],\n",
    "['يونس\"','Jonas'],\n",
    "\n",
    "['هود','Hud'],\n",
    "['يوسف',\"Joseph\"],\n",
    "['الرعد','The Thunder'],\n",
    "['ابراهيم','Abraham'],\n",
    "['الحجر','Al-Hijr'],\n",
    "['النحل',\"An-Nahl\"],\n",
    "['الإسراء','Al-Israa'],\n",
    "['الكهف','Al-Kahf'],\n",
    "['مريم','Mary'],\n",
    "['طه',\"Taa-Haa\"],\n",
    "\n",
    "\n",
    "['الأنبياء','The Prophets'],\n",
    "['الحج',\"The Pilgrimage\"],\n",
    "['المؤمنون','Al-Muminoon'],\n",
    "['النور','An-Noor'],\n",
    "['الفرقان','Al-Furqaan'],\n",
    "['الشعراء',\"Ash-Shu'araa\"],\n",
    "['النمل','An-Naml'],\n",
    "['القصص','The Stories'],\n",
    "['العنكبوت','The Spider'],\n",
    "['الروم',\"Ar-Room\"],\n",
    "\n",
    "\n",
    "['لقمان','Luqman'],\n",
    "['السجدة',\"As-Sajda\"],\n",
    "['الأحزاب','Al-Ahzaab'],\n",
    "['سبإ','Saba'],\n",
    "['فاطر','The Originator'],\n",
    "['يس',\"Yaseen\"],\n",
    "['الصافات','As-Saaffaat'],\n",
    "['ص','Saad'],\n",
    "['الزمر','Az-Zumar'],\n",
    "['غافر',\"Al-Ghaafir\"],\n",
    "\n",
    "\n",
    "['فصلت','Explained in detail'],\n",
    "['الشورى',\"Ash-Shura\"],\n",
    "['الزخرف','Ornaments of gold'],\n",
    "['الدخان','Ad-Dukhaan'],\n",
    "['الجاثية','Crouching'],\n",
    "['الأحقاف',\"Al-Ahqaf\"],\n",
    "['محمد','Muhammad'],\n",
    "['الفتح','Al-Fath'],\n",
    "['الحجرات','Al-Hujuraat'],\n",
    "['ق',\"Qaaf\"],\n",
    "\n",
    "\n",
    "['الذاريات','The Winnowing Winds'],\n",
    "['الطور',\"The Mount\"],\n",
    "['النجم','An-Najm'],\n",
    "['القمر','Al-Qamar'],\n",
    "['الرحمن','Ar-Rahmaan'],\n",
    "['الواقعة',\"The Inevitable\"],\n",
    "['الحديد','Al-Hadid'],\n",
    "['المجادلة','Al-Mujaadila'],\n",
    "['الحشر','The Exile'],\n",
    "['الممتحنة',\"Al-Mumtahana\"],\n",
    "\n",
    "\n",
    "['الصف','The Ranks'],\n",
    "['الجمعة',\"Al-Jumu'a\"],\n",
    "['المنافقون','Al-Munaafiqoon'],\n",
    "['التغابن','Mutual Disillusion'],\n",
    "['الطلاق','At-Talaaq'],\n",
    "['التحريم',\"At-Tahrim\"],\n",
    "['الملك','Al-Mulk'],\n",
    "['القلم','Al-Qalam'],\n",
    "['الحاقة','Al-Haaqqa'],\n",
    "['المعارج',\"The Ascending Stairways\"],\n",
    "\n",
    "\n",
    "['نوح','Nooh'],\n",
    "['الجن',\"Al-Jinn\"],\n",
    "['المزمل','Al-Muzzammil'],\n",
    "['المدثر','Al-Muddaththir'],\n",
    "['القيامة','Al-Qiyaama'],\n",
    "['الانسان',\"Man\"],\n",
    "['المرسلات','The Emissaries'],\n",
    "['النبإ','An-Naba'],\n",
    "['النازعات','Those who drag forth'],\n",
    "['عبس',\"He frowned\"],\n",
    "\n",
    "\n",
    "['التكوير','At-Takwir'],\n",
    "['الإنفطار',\"Al-Infitaar\"],\n",
    "['المطففين','Al-Mutaffifin'],\n",
    "['الإنشقاق','Al-Inshiqaaq'],\n",
    "['البروج','Al-Burooj'],\n",
    "['الطارق',\"At-Taariq\"],\n",
    "['الأعلى',\"Al-A'laa\"],\n",
    "['الغاشية','Al-Ghaashiya'],\n",
    "['الفجر','Al-Fajr'],\n",
    "['البلد',\"Al-Balad\"],\n",
    "\n",
    "\n",
    "['الشمس','Ash-Shams'],\n",
    "['الليل',\"Al-Lail\"],\n",
    "['الضحى','The Morning Hours'],\n",
    "['الشرح','Ash-Sharh'],\n",
    "['التين','The Fig'],\n",
    "['العلق',\"The Clot\"],\n",
    "['القدر',\"The Power, Fate\"],\n",
    "['البينة','The Evidence'],\n",
    "['الزلزلة','Az-Zalzala'],\n",
    "['العاديات',\"Al-Aadiyaat\"],\n",
    "\n",
    "\n",
    "['القارعة','The Calamity'],\n",
    "['التكاثر',\"Competition\"],\n",
    "['العصر','The Declining Day, Epoch'],\n",
    "['الهمزة','The Traducer'],\n",
    "['الفيل','Al-Fil'],\n",
    "['قريش',\"Quraish\"],\n",
    "['الماعون',\"Almsgiving\"],\n",
    "['الكوثر','Al-Kawthar'],\n",
    "['الكافرون','The Disbelievers'],\n",
    "['النصر',\"Divine Support\"],\n",
    "\n",
    "\n",
    "['المسد',\"Al-Masad\"],\n",
    "['الإخلاص','Sincerity'],\n",
    "['الفلق','Al-Falaq'],\n",
    "['الناس',\"Mankind\"]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc979d62",
   "metadata": {},
   "source": [
    "### Function to Add Quranic References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "89b25106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_add_quran_ref(q_dua, surah_index, complete_ref, norm_surah_name, orig_surah_name):\n",
    "\n",
    "    verse_index = int(re.sub('[^0-9]+', '', complete_ref))\n",
    "#     print(\"Verse index = \", verse_index)\n",
    "#     print(\"Surah index = \", surah_index)\n",
    "#     print(\"Surah name = \", norm_surah_name)\n",
    "#     print(\"Org Surah name = \", orig_surah_name)\n",
    "\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX qo:<http://quranontology.com/Resource/>\n",
    "    PREFIX rdf:<http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT Distinct ?verse ?vIndex ?cIndex\n",
    "    {\n",
    "      ?verse a qo:Verse.\n",
    "      ?verse qo:VerseIndex ?vIndex.\n",
    "      ?verse qo:ChapterIndex ?cIndex.\n",
    "      ?verse qo:IsPartOf ?chapter.\n",
    "      ?chapter rdfs:label ?chapName. \n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    qres = g_Quran.query(query, initBindings={\"vIndex\": Literal(verse_index, datatype=XSD.nonNegativeInteger),\n",
    "                                              \"cIndex\": Literal(surah_index, datatype=XSD.nonNegativeInteger) })\n",
    "\n",
    "    \n",
    "    for row in qres:\n",
    "        g_dua.add((q_dua, qn.IsPartOf, row.verse))\n",
    "        print(\"Added triple: \\n\", q_dua, qn.IsPartOf, row.verse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd8ef5",
   "metadata": {},
   "source": [
    "### Function to add Hadith References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1cd0b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_add_hadith_ref(h_dua, hadith_IRI):\n",
    "#     print(h_dua)\n",
    "#     print(hadith_IRI)\n",
    "\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs:<http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX :<http://www.i-knex.com/ontology/hadith#>\n",
    "    PREFIX rdf:<http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT distinct ?hadith WHERE\n",
    "    {\n",
    "      ?hadith rdf:type :Hadith.\n",
    "      FILTER (?hadith = <\"\"\"+hadith_IRI+\"\"\">)\n",
    "    }\n",
    "    \"\"\"\n",
    "    qres = g_Hadith.query(query)\n",
    "\n",
    "    for row in qres:\n",
    "        g_dua.add((h_dua, hn.isPartOfHadith, row.hadith))\n",
    "        print(\"Added Triple: \\n\", f' {h_dua} {hn.isPartOfHadith} {row.hadith}')\n",
    "        \n",
    "\n",
    "#     for row in qres:\n",
    "#         print(row.hadith)\n",
    "#         if row.hadith.toPython() == hadith_IRI:\n",
    "#             g.add((h_dua, hn.isPartOfHadith, row.hadith))\n",
    "#             g.add((row.hadith, hn.isPartOfChapter, row.hChap))\n",
    "#             g.add((row.Chap, hn.isPartOfBook, row.hBook))\n",
    "#             g.add((row.hBook, hn.isPartOfCollection, row.hCollect))\n",
    "#             g.add((row.hCollect, hn.collectionName, row.hCollectName))\n",
    "\n",
    "#             print(\"Linked dua: \", h_dua.toPython())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5328496",
   "metadata": {},
   "source": [
    "### Function to add Cateogries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e588454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Categories(file_name):\n",
    "    # Make categories first: Read dua_category_map-v80.csv\n",
    "    with open(file_name, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        csvreader = csv.DictReader(file)\n",
    "        #print(csvreader)\n",
    "\n",
    "        count = 0\n",
    "        for row in csvreader:\n",
    "            cat = URIRef(str(n)+ \"Category-\"+str(row[\"category\"]))\n",
    "            g_dua.add((cat, RDF.type, n.Category))\n",
    "            g_dua.add((cat, n.categoryId, Literal(row[\"id\"], datatype=XSD.nonNegativeInteger)))\n",
    "            g_dua.add((cat, n.categoryUrduTitle, Literal(row[\"title_ur\"], datatype = XSD.string)))\n",
    "            g_dua.add((cat, n.categoryEnglishTitle, Literal(row[\"title_en\"], datatype = XSD.string)))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c827777",
   "metadata": {},
   "source": [
    "### Function to add Duas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e9c83aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duas(file_name):\n",
    "    count = 0\n",
    "    \n",
    "    with open(file_name, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        csvreader = csv.DictReader(file)\n",
    "\n",
    "        with open('./IRIConstruction/Dua_modified.csv', 'r', encoding='utf-8', errors='replace') as file2:\n",
    "            csvreader2 = csv.DictReader(file2)\n",
    "\n",
    "            for row in csvreader:\n",
    "                \n",
    "                try:\n",
    "                    data = next(csvreader2)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                \n",
    "                if row[\"duaArabic\"] != \"Sample\":\n",
    "                    dua = URIRef(str(n)+\"Dua-\"+str(row[\"duaId\"]))\n",
    "                    g_dua.add((dua, RDF.type, n.Dua))\n",
    "\n",
    "                    g_dua.add((dua, n.duaId, Literal(row[\"dua_id\"], datatype = XSD.nonNegativeInteger)))\n",
    "                    g_dua.add((dua, n.duaUrduTitle, Literal(row[\"duaTitle_ur\"], datatype = XSD.string)))\n",
    "                    g_dua.add((dua, n.duaEnglishTitle, Literal(row[\"duaTitle_en\"], datatype = XSD.string)))\n",
    "\n",
    "                    g_dua.add((dua, n.duaArabicText, Literal(row[\"duaArabic\"], datatype = XSD.string)))\n",
    "                    g_dua.add((dua, n.duaEnglishText, Literal(row[\"dua_en\"], datatype = XSD.string)))\n",
    "                    g_dua.add((dua, n.duaUrduText, Literal(row[\"dua_ur\"], datatype = XSD.string)))\n",
    "\n",
    "                    if row[\"duaType_en\"] == \"Qurani Dua\":\n",
    "                        g_dua.add((dua, RDF.type, n.QuranicDua))\n",
    "                        g_dua.add((dua, n.duaType, Literal(\"Qurani Dua\", datatype = XSD.string)))\n",
    "\n",
    "                        surah_index = 1\n",
    "                        for s in q_surah_lis:\n",
    "                            if row[\"duaReference_ur\"].find('-') == -1:\n",
    "                                # not considering verse ranges for now\n",
    "\n",
    "                                tokenized_csv_ref = tokenize(row[\"duaReference_ur\"], conditions=is_arabicrange, morphs=strip_tashkeel)\n",
    "                                normalized_csv_ref = normalizeArabic(deNoise(row[\"duaReference_ur\"]))\n",
    "                                tokenized_surah = tokenize(s[0], conditions=is_arabicrange, morphs=strip_tashkeel)\n",
    "                                normalized_surah = normalizeArabic(deNoise(s[0]))                \n",
    "                                csv_ref_arabic = re.sub('[0-9 ()]+', '', normalizeArabic(deNoise(row[\"duaReference_ur\"])))\n",
    "\n",
    "                                if normalized_csv_ref.find(normalized_surah) != -1 and abs(len(csv_ref_arabic)-len(normalized_surah)) <= 2:\n",
    "                                    print(\"same\")\n",
    "                                    find_add_quran_ref(dua, surah_index, normalized_csv_ref, normalized_surah, s[0])\n",
    "                                    count+=1\n",
    "                            else:\n",
    "                                # considering verse ranges now, but not commas\n",
    "                                if row[\"duaReference_ur\"].find(',') == -1:\n",
    "\n",
    "                                    tokenized_csv_ref = tokenize(row[\"duaReference_ur\"], conditions=is_arabicrange, morphs=strip_tashkeel)\n",
    "                                    normalized_csv_ref = normalizeArabic(deNoise(row[\"duaReference_ur\"]))\n",
    "                                    ref_verse_range =  re.sub('[^0-9\\-]', '', normalized_csv_ref)\n",
    "                                    verse_range_ends = ref_verse_range.split('-')\n",
    "                                    for i in range(len(verse_range_ends)):\n",
    "                                        verse_range_ends[i] = int(verse_range_ends[i])\n",
    "                                    # print(\"Verse range = \", verse_range_ends)\n",
    "\n",
    "                                    tokenized_surah = tokenize(s[0], conditions=is_arabicrange, morphs=strip_tashkeel)\n",
    "                                    normalized_surah = normalizeArabic(deNoise(s[0]))\n",
    "                                    # if len(tokenize(s[0], conditions=is_arabicrange, morphs=strip_tashkeel))<=2 and normalizeArabic(deNoise(row[\"duaReference_ur\"])).find(normalizeArabic(deNoise(s[0]))) == 0 and (len(tokenize(s[0], conditions=is_arabicrange, morphs=strip_tashkeel)[0]) > len(normalizeArabic(deNoise(row[\"duaReference_ur\"])))+1  or  len(tokenize(s[0], conditions=is_arabicrange, morphs=strip_tashkeel)[0]) +1 < len(normalizeArabic(deNoise(row[\"duaReference_ur\"])))+1):\n",
    "\n",
    "                                    csv_ref_arabic = re.sub('[0-9 ()]+', '', normalizeArabic(deNoise(row[\"duaReference_ur\"])))\n",
    "\n",
    "                                    if normalized_csv_ref.find(normalized_surah) != -1 and abs(len(csv_ref_arabic)-len(normalized_surah)) <= 2:\n",
    "                                        print(\"not same\")\n",
    "                                        for v in verse_range_ends:\n",
    "                                            pos = re.search(r\"\\d\", normalized_csv_ref)\n",
    "                                            print(pos.start())\n",
    "                                            new_normalized_csv_ref = re.sub('[0123456789-]','',normalized_csv_ref)\n",
    "                                            new_normalized_csv_ref = new_normalized_csv_ref[:pos.start()] + str(v) + new_normalized_csv_ref[pos.start():]\n",
    "                                            print(new_normalized_csv_ref)\n",
    "                                            find_add_quran_ref(dua, surah_index, new_normalized_csv_ref, normalized_surah, s[0])\n",
    "                            surah_index +=1\n",
    "                    else:\n",
    "                        g_dua.add((dua, RDF.type, n.HadithDua))\n",
    "                        g_dua.add((dua, n.duaType, Literal(row[\"duaType_en\"], datatype = XSD.string)))\n",
    "                        if data[\"Dua_IRI\"]:\n",
    "                            find_add_hadith_ref(dua, data[\"Dua_IRI\"])\n",
    "\n",
    "\n",
    "    print(\"Counts of found surahs = \", count)\n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fad4b9",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee446d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Triple: \n",
      "  http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-06 http://www.i-knex.com/ontology/hadith#isPartOfHadith http://www.i-knex.com/ontology/hadith#SB-HD6358\n",
      "Added Triple: \n",
      "  http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-07 http://www.i-knex.com/ontology/hadith#isPartOfHadith http://www.i-knex.com/ontology/hadith#SB-HD3370\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-10 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran17-24\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-11 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran28-24\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-13 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran23-118\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-15 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran17-80\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-16 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran23-29\n",
      "not same\n",
      "13\n",
      "( المءمنون : 98 )\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-18 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran23-98\n",
      "13\n",
      "( المءمنون : 97 )\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-18 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran23-97\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-22 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran27-19\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-23 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran46-15\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-24 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran2-201\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-26 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran60-4\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-29 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran25-74\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-30 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran7-126\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-31 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran2-250\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-33 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran3-8\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-34 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran3-16\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-35 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran7-23\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-36 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran3-147\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-37 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran59-10\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-38 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran3-193\n",
      "same\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-39 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran3-194\n",
      "not same\n",
      "12\n",
      "( الفرقان : 66)\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-40 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran25-66\n",
      "12\n",
      "( الفرقان : 65)\n",
      "Added triple: \n",
      " http://www.semanticweb.org/szm/dua-ontology#Dua-QuranicDua-40 http://quranontology.com/Resource/IsPartOf http://quranontology.com/Resource/quran25-65\n",
      "not same\n",
      "12\n",
      "( ال عمران :192 )\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    add_Categories('Duaein Data - For KG - revisedCategories-v57.csv')\n",
    "    \n",
    "    add_duas('Duaein Data - For KG - duas-test-v80.csv')\n",
    "\n",
    "    #g.serialize(destination='Populated_Dua_KG.ttl', format='turtle')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     qres = g_dua.query(\n",
    "#     \"\"\"\n",
    "#         PREFIX : <http://www.semanticweb.org/szm/dua-ontology#>\n",
    "#         SELECT ?s ?p ?o \n",
    "#         WHERE {\n",
    "#             ?s rdf:type :Category .\n",
    "#             ?s ?p ?o.\n",
    "#         }\n",
    "#     \"\"\"\n",
    "#     )\n",
    "\n",
    "#     print('Following are the Categories \\n')\n",
    "#     # Print the results\n",
    "#     for row in qres:\n",
    "#         print(f'{row.s}  {row.p}   {row.o} \\n')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ff2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
